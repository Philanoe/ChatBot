{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#from torch.utils.data import Dataset\nos.environ[\"TOKENIZERS_PARALLELISM\"]=\"true\"\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n!pip install -Uqq datasets\n!pip install -Uqq wandb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check if the environment variable was set correctly\nprint(os.environ.get('TOKENIZERS_PARALLELISM', ''))\nprint(os.environ.get('WANDB_DISABLED', ''))","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:17:33.371445Z","iopub.execute_input":"2022-03-26T10:17:33.371714Z","iopub.status.idle":"2022-03-26T10:17:33.379195Z","shell.execute_reply.started":"2022-03-26T10:17:33.371686Z","shell.execute_reply":"2022-03-26T10:17:33.378357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport json\nimport datasets #Hugging Face library\nfrom transformers import DataCollatorWithPadding\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk(ModelPath):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-26T10:17:34.965273Z","iopub.execute_input":"2022-03-26T10:17:34.965815Z","iopub.status.idle":"2022-03-26T10:17:34.970797Z","shell.execute_reply.started":"2022-03-26T10:17:34.96578Z","shell.execute_reply":"2022-03-26T10:17:34.969865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# First part : train a sentence classifier with the entire available data","metadata":{}},{"cell_type":"code","source":"# read json data as a dictionary \nwith open('../input/intent-recognition-chatbot-corpus-from-askubuntu/AskUbuntu Corpus.json', 'r') as f:\n  data = json.load(f)\n# Intent and Text information are stored in the value corresponding to sentences key \nsentences=data[\"sentences\"]\n# Get intent content using list comprehension by looping in the sentences values \nlabelList=[i[\"intent\"]for i in sentences]\n# Get text content using list comprehension by looping in the sentences values \ntextList=[i['text'] for i in sentences]","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:17:39.115721Z","iopub.execute_input":"2022-03-26T10:17:39.11599Z","iopub.status.idle":"2022-03-26T10:17:39.126211Z","shell.execute_reply.started":"2022-03-26T10:17:39.115961Z","shell.execute_reply":"2022-03-26T10:17:39.125437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create IntentDataFrame with label list and text list\nDFData = {'label' : labelList, 'sentence' : textList}\nIntentDataFrame = pd.DataFrame(data = DFData)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:17:41.462249Z","iopub.execute_input":"2022-03-26T10:17:41.462704Z","iopub.status.idle":"2022-03-26T10:17:41.467115Z","shell.execute_reply.started":"2022-03-26T10:17:41.462666Z","shell.execute_reply":"2022-03-26T10:17:41.466433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Delete the samples with \"None\" as label\nIntentDataFrame=IntentDataFrame[IntentDataFrame[\"label\"]!=\"None\"]","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:17:42.418624Z","iopub.execute_input":"2022-03-26T10:17:42.41934Z","iopub.status.idle":"2022-03-26T10:17:42.423884Z","shell.execute_reply.started":"2022-03-26T10:17:42.419306Z","shell.execute_reply":"2022-03-26T10:17:42.422963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check whether the training values are quite balanced\nIntentDataFrame[\"label\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:17:44.364621Z","iopub.execute_input":"2022-03-26T10:17:44.365154Z","iopub.status.idle":"2022-03-26T10:17:44.374193Z","shell.execute_reply.started":"2022-03-26T10:17:44.365115Z","shell.execute_reply":"2022-03-26T10:17:44.372324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replace the labels strings by label numbers (should be automated for larger labels sets)\nLabelToIndex = {\"Software Recommendation\":0,\"Make Update\":1,\"Shutdown Computer\":2,\"Setup Printer\":3}\nIntentDataFrame[\"label\"]=IntentDataFrame[\"label\"].map(LabelToIndex)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:17:45.407083Z","iopub.execute_input":"2022-03-26T10:17:45.407569Z","iopub.status.idle":"2022-03-26T10:17:45.415493Z","shell.execute_reply.started":"2022-03-26T10:17:45.407533Z","shell.execute_reply":"2022-03-26T10:17:45.412414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert train_df to a dataset so that it can be used by Hugging Face models and tokenizers\ntrain_dataset=datasets.Dataset.from_pandas(IntentDataFrame)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:17:54.729192Z","iopub.execute_input":"2022-03-26T10:17:54.729788Z","iopub.status.idle":"2022-03-26T10:17:54.736755Z","shell.execute_reply.started":"2022-03-26T10:17:54.729747Z","shell.execute_reply":"2022-03-26T10:17:54.736074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:17:55.458511Z","iopub.execute_input":"2022-03-26T10:17:55.459271Z","iopub.status.idle":"2022-03-26T10:17:55.464942Z","shell.execute_reply.started":"2022-03-26T10:17:55.459224Z","shell.execute_reply":"2022-03-26T10:17:55.464233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove __index_level_0__ columns\ntrain_dataset=train_dataset.remove_columns([\"__index_level_0__\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:17:56.425061Z","iopub.execute_input":"2022-03-26T10:17:56.425606Z","iopub.status.idle":"2022-03-26T10:17:56.430791Z","shell.execute_reply.started":"2022-03-26T10:17:56.425564Z","shell.execute_reply":"2022-03-26T10:17:56.430111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import AutoTokenizer with checkpoint\"distilbert-base-uncased\"\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:17:57.716034Z","iopub.execute_input":"2022-03-26T10:17:57.716305Z","iopub.status.idle":"2022-03-26T10:18:01.479351Z","shell.execute_reply.started":"2022-03-26T10:17:57.716276Z","shell.execute_reply":"2022-03-26T10:18:01.478611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenization work on train_dataset\ndef preprocess_function(examples):\n    return tokenizer(examples[\"sentence\"], truncation=True, padding=True)\ntokenize_train=train_dataset.map(preprocess_function,batched=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:18:01.480765Z","iopub.execute_input":"2022-03-26T10:18:01.480996Z","iopub.status.idle":"2022-03-26T10:18:01.54265Z","shell.execute_reply.started":"2022-03-26T10:18:01.480962Z","shell.execute_reply":"2022-03-26T10:18:01.541963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data_collator\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:18:01.543729Z","iopub.execute_input":"2022-03-26T10:18:01.545328Z","iopub.status.idle":"2022-03-26T10:18:01.556258Z","shell.execute_reply.started":"2022-03-26T10:18:01.545288Z","shell.execute_reply":"2022-03-26T10:18:01.555393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build model \n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=4)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:18:06.887677Z","iopub.execute_input":"2022-03-26T10:18:06.888266Z","iopub.status.idle":"2022-03-26T10:18:15.011686Z","shell.execute_reply.started":"2022-03-26T10:18:06.888229Z","shell.execute_reply":"2022-03-26T10:18:15.010988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model fine tuning training\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=7,\n    weight_decay=0.01,\n    #evaluation_strategy=\"epoch\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenize_train,\n    #eval_dataset=tokenize_test,  Here, we work with the entire dataset as training data\n    #compute_metrics=compute_metrics,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)\n\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:18:15.013489Z","iopub.execute_input":"2022-03-26T10:18:15.013765Z","iopub.status.idle":"2022-03-26T10:18:26.575789Z","shell.execute_reply.started":"2022-03-26T10:18:15.013728Z","shell.execute_reply":"2022-03-26T10:18:26.57507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Second part : define the function making the prediction from a sentence input (string), based on the model trained above","metadata":{}},{"cell_type":"code","source":"def SentenceClassifier(InputSentence):\n    \"\"\" Take a sentence as input, return the corresponding label\n    \n    dependencies : tokenizer, trainer\n    \"\"\"\n    \n    def preprocess_function(examples):\n        return tokenizer(examples[\"sentence\"], truncation=True, padding=True)\n    \n    # here, we are keeping the input as a Dataset, which could allow us to reuse the code\n    # to answer many questions at once\n    InputSentenceDFData = {'sentence' : [InputSentence]}\n    InputSentenceDataFrame = pd.DataFrame(data = InputSentenceDFData)\n    InputSentenceDataset = datasets.Dataset.from_pandas(InputSentenceDataFrame)\n    Tokenised_InputSentence = InputSentenceDataset.map(preprocess_function,batched=False)\n    \n    LabelScores = trainer.predict(Tokenised_InputSentence)\n    BestLabel = LabelScores.predictions.argmax(1)\n    \n    IndexToLabel = {0:\"Software Recommendation\",1:\"Make Update\",2:\"Shutdown Computer\",3:\"Setup Printer\"}\n    OutputLabelName = IndexToLabel[BestLabel[0]]\n    \n    return OutputLabelName","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:18:52.96315Z","iopub.execute_input":"2022-03-26T10:18:52.963627Z","iopub.status.idle":"2022-03-26T10:18:52.97157Z","shell.execute_reply.started":"2022-03-26T10:18:52.963592Z","shell.execute_reply":"2022-03-26T10:18:52.970843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"InputSentence = \"What should I use to cut pictures ?\"\nOutputLabel = SentenceClassifier(InputSentence)\nprint(f'Your question was : \"{InputSentence}\" it was classified as : \"{OutputLabel}\"')","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:06:18.733369Z","iopub.status.idle":"2022-03-26T10:06:18.733776Z","shell.execute_reply.started":"2022-03-26T10:06:18.733552Z","shell.execute_reply":"2022-03-26T10:06:18.733575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Third part : saving and reloading the model to avoid downloading it from Hugging face\n# and avoid repeating the training process","metadata":{}},{"cell_type":"code","source":"# Save the model and tokenizer locally\nos.mkdir(\"/kaggle/working/model/\")\nos.mkdir(\"/kaggle/working/tokenizer/\")\n\nModelPath = \"/kaggle/working/model/\"\nTokenizerPath = \"/kaggle/working/tokenizer/\"\n\nif os.path.isdir(ModelPath):\n    model.save_pretrained(ModelPath)\n    print(\"model ok\")\nif os.path.isdir(TokenizerPath):\n    tokenizer.save_pretrained(TokenizerPath)\n    print(\"tokenizer ok\")","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:21:40.302379Z","iopub.execute_input":"2022-03-26T10:21:40.302853Z","iopub.status.idle":"2022-03-26T10:21:40.853786Z","shell.execute_reply.started":"2022-03-26T10:21:40.302817Z","shell.execute_reply":"2022-03-26T10:21:40.852838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('./tokenizer')","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:21:47.671747Z","iopub.execute_input":"2022-03-26T10:21:47.672272Z","iopub.status.idle":"2022-03-26T10:21:47.677824Z","shell.execute_reply.started":"2022-03-26T10:21:47.672232Z","shell.execute_reply":"2022-03-26T10:21:47.677121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('./model')","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:21:51.040911Z","iopub.execute_input":"2022-03-26T10:21:51.041626Z","iopub.status.idle":"2022-03-26T10:21:51.047331Z","shell.execute_reply.started":"2022-03-26T10:21:51.041578Z","shell.execute_reply":"2022-03-26T10:21:51.046591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the model and tokenizer from a local path\\\nLocalModel = AutoModelForSequenceClassification.from_pretrained(ModelPath,num_labels=4)\nLocalTokenizer = AutoTokenizer.from_pretrained(TokenizerPath)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:22:05.706825Z","iopub.execute_input":"2022-03-26T10:22:05.707368Z","iopub.status.idle":"2022-03-26T10:22:06.513888Z","shell.execute_reply.started":"2022-03-26T10:22:05.707332Z","shell.execute_reply":"2022-03-26T10:22:06.513178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check if the classifier works well with the local data","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:06:18.74933Z","iopub.status.idle":"2022-03-26T10:06:18.750238Z","shell.execute_reply.started":"2022-03-26T10:06:18.749979Z","shell.execute_reply":"2022-03-26T10:06:18.750002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def LocalSentenceClassifier(InputSentence):\n    \"\"\" Take a sentence as input, return the corresponding label\n    \n    dependencies : LocalTokenizer, LocalModel\n    We use tokenizer2 and trainer2 instead of tokeninzer and trainer\n    to be sure that this function works with the data saved and load locally\n    \"\"\"\n    \n    trainer = Trainer(\n        model=LocalModel,\n        args=training_args,\n        train_dataset=tokenize_train,\n        #eval_dataset=tokenize_test,  Here, we work with the entire dataset as training data\n        #compute_metrics=compute_metrics,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n    )\n    \n    def preprocess_function(examples):\n        return LocalTokenizer(examples[\"sentence\"], truncation=True, padding=True)\n    \n    # here, we are keeping the input as a Dataset, which could allow us to reuse the code\n    # to answer many questions at once\n    InputSentenceDFData = {'sentence' : [InputSentence]}\n    InputSentenceDataFrame = pd.DataFrame(data = InputSentenceDFData)\n    InputSentenceDataset = datasets.Dataset.from_pandas(InputSentenceDataFrame)\n    Tokenised_InputSentence = InputSentenceDataset.map(preprocess_function,batched=False)\n    \n    LabelScores = trainer.predict(Tokenised_InputSentence)\n    BestLabel = LabelScores.predictions.argmax(1)\n    \n    IndexToLabel = {0:\"Software Recommendation\",1:\"Make Update\",2:\"Shutdown Computer\",3:\"Setup Printer\"}\n    OutputLabelName = IndexToLabel[BestLabel[0]]\n    \n    return OutputLabelName","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:22:22.767622Z","iopub.execute_input":"2022-03-26T10:22:22.768301Z","iopub.status.idle":"2022-03-26T10:22:22.776546Z","shell.execute_reply.started":"2022-03-26T10:22:22.768264Z","shell.execute_reply":"2022-03-26T10:22:22.775753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tokenizer)\nprint(\"-----------\")\nprint(tokenizer2)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:06:18.753308Z","iopub.status.idle":"2022-03-26T10:06:18.754186Z","shell.execute_reply.started":"2022-03-26T10:06:18.753922Z","shell.execute_reply":"2022-03-26T10:06:18.753946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"InputSentence = \"How can I update Ubuntu ?\"\nOutputLabel = LocalSentenceClassifier(InputSentence)\nprint(f'Your question was : \"{InputSentence}\" it was classified as : \"{OutputLabel}\"')","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:22:32.190446Z","iopub.execute_input":"2022-03-26T10:22:32.190705Z","iopub.status.idle":"2022-03-26T10:22:32.341013Z","shell.execute_reply.started":"2022-03-26T10:22:32.190676Z","shell.execute_reply":"2022-03-26T10:22:32.340205Z"},"trusted":true},"execution_count":null,"outputs":[]}]}