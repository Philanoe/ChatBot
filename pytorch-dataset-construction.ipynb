{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-14T16:18:52.827901Z","iopub.execute_input":"2022-03-14T16:18:52.828200Z","iopub.status.idle":"2022-03-14T16:18:52.840467Z","shell.execute_reply.started":"2022-03-14T16:18:52.828167Z","shell.execute_reply":"2022-03-14T16:18:52.839681Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"/kaggle/input/intent-recognition-chatbot-corpus-from-askubuntu/AskUbuntu Corpus.json\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\n# read json data as a dictionary \nwith open('../input/intent-recognition-chatbot-corpus-from-askubuntu/AskUbuntu Corpus.json', 'r') as f:\n  data = json.load(f)\n# Intent and Text information are stored in the value corresponding to sentences key \n#sentences=data[\"sentences\"]\n# Get intent content using list comprehension by looping in the sentences values \nlabelList=[i[\"intent\"]for i in sentences]\n# Get text content using list comprehension by looping in the sentences values \ntextList=[i['text'] for i in sentences]","metadata":{"execution":{"iopub.status.busy":"2022-03-14T16:18:52.842361Z","iopub.execute_input":"2022-03-14T16:18:52.843518Z","iopub.status.idle":"2022-03-14T16:18:52.858896Z","shell.execute_reply.started":"2022-03-14T16:18:52.843479Z","shell.execute_reply":"2022-03-14T16:18:52.858091Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"DFData = {'label' : labelList, 'sentence' : textList}\nIntentSeriesDataFrame = pd.DataFrame(data = DFData)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T16:18:52.863232Z","iopub.execute_input":"2022-03-14T16:18:52.863433Z","iopub.status.idle":"2022-03-14T16:18:52.873101Z","shell.execute_reply.started":"2022-03-14T16:18:52.863407Z","shell.execute_reply":"2022-03-14T16:18:52.872483Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#IntentSeriesDataFrame","metadata":{"execution":{"iopub.status.busy":"2022-03-14T16:18:52.904215Z","iopub.execute_input":"2022-03-14T16:18:52.904453Z","iopub.status.idle":"2022-03-14T16:18:52.910043Z","shell.execute_reply.started":"2022-03-14T16:18:52.904426Z","shell.execute_reply":"2022-03-14T16:18:52.908908Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# get the list of labels\n#LabelSeries = pd.Series(labelList)\n#print(LabelSeries.unique())\n# Convert label string value to label integer value. For example: To convert Software Recommendation to 0\nIntentSeriesDataFrame[\"label\"]=IntentSeriesDataFrame[\"label\"].map({\"Software Recommendation\":0,\"Make Update\":1,\"Shutdown Computer\":2,\"Setup Printer\":3,\"None\":4})\n# Count the number for each label value\n#print(IntentSeriesDataFrame[\"label\"].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-03-14T16:18:52.911797Z","iopub.execute_input":"2022-03-14T16:18:52.912625Z","iopub.status.idle":"2022-03-14T16:18:52.927652Z","shell.execute_reply.started":"2022-03-14T16:18:52.912588Z","shell.execute_reply":"2022-03-14T16:18:52.926783Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"#from torch.utils.data import Dataset\n!pip install -Uqq datasets\nimport datasets #Hugging Face library","metadata":{"execution":{"iopub.status.busy":"2022-03-14T16:18:52.931477Z","iopub.execute_input":"2022-03-14T16:18:52.931864Z","iopub.status.idle":"2022-03-14T16:19:01.132340Z","shell.execute_reply.started":"2022-03-14T16:18:52.931835Z","shell.execute_reply":"2022-03-14T16:19:01.131514Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"imdb = datasets.DatasetDict()\n#https://huggingface.co/docs/datasets/loading\nTrainingDataset = datasets.Dataset.from_pandas(IntentSeriesDataFrame)\nimdb[\"train\"] = TrainingDataset\nimdb","metadata":{"execution":{"iopub.status.busy":"2022-03-14T16:19:01.137064Z","iopub.execute_input":"2022-03-14T16:19:01.137289Z","iopub.status.idle":"2022-03-14T16:19:01.151084Z","shell.execute_reply.started":"2022-03-14T16:19:01.137263Z","shell.execute_reply":"2022-03-14T16:19:01.150106Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'sentence'],\n        num_rows: 162\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2022-03-14T16:19:01.153069Z","iopub.execute_input":"2022-03-14T16:19:01.153250Z","iopub.status.idle":"2022-03-14T16:19:11.480109Z","shell.execute_reply.started":"2022-03-14T16:19:01.153227Z","shell.execute_reply":"2022-03-14T16:19:11.479363Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\nModel config DistilBertConfig {\n  \"_name_or_path\": \"distilbert-base-uncased\",\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForMaskedLM\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"initializer_range\": 0.02,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.15.0\",\n  \"vocab_size\": 30522\n}\n\nloading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\nloading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\nloading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\nloading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\nloading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\nloading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\nModel config DistilBertConfig {\n  \"_name_or_path\": \"distilbert-base-uncased\",\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForMaskedLM\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"initializer_range\": 0.02,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.15.0\",\n  \"vocab_size\": 30522\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"sentence\"], truncation=True, padding=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T16:19:11.481503Z","iopub.execute_input":"2022-03-14T16:19:11.481750Z","iopub.status.idle":"2022-03-14T16:19:11.488765Z","shell.execute_reply.started":"2022-03-14T16:19:11.481715Z","shell.execute_reply":"2022-03-14T16:19:11.488093Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"tokenized_imdb = {}\ntokenized_imdb['train'] = imdb[\"train\"].map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T16:19:11.490102Z","iopub.execute_input":"2022-03-14T16:19:11.490680Z","iopub.status.idle":"2022-03-14T16:19:11.566347Z","shell.execute_reply.started":"2022-03-14T16:19:11.490641Z","shell.execute_reply":"2022-03-14T16:19:11.565273Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88d3dea50c0546a69cf4dfc8bd9e957b"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_imdb[\"train\"]","metadata":{"execution":{"iopub.status.busy":"2022-03-14T16:19:11.567567Z","iopub.execute_input":"2022-03-14T16:19:11.568282Z","iopub.status.idle":"2022-03-14T16:19:11.575709Z","shell.execute_reply.started":"2022-03-14T16:19:11.568244Z","shell.execute_reply":"2022-03-14T16:19:11.574804Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['label', 'sentence', 'input_ids', 'attention_mask'],\n    num_rows: 162\n})"},"metadata":{}}]},{"cell_type":"code","source":"#tokenized_imdb[\"train\"][\"input_ids\"]","metadata":{"execution":{"iopub.status.busy":"2022-03-14T16:19:11.577373Z","iopub.execute_input":"2022-03-14T16:19:11.578370Z","iopub.status.idle":"2022-03-14T16:19:11.583382Z","shell.execute_reply.started":"2022-03-14T16:19:11.578330Z","shell.execute_reply":"2022-03-14T16:19:11.582412Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T16:19:11.586117Z","iopub.execute_input":"2022-03-14T16:19:11.586798Z","iopub.status.idle":"2022-03-14T16:19:11.592568Z","shell.execute_reply.started":"2022-03-14T16:19:11.586740Z","shell.execute_reply":"2022-03-14T16:19:11.591845Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\nmodel = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=5)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T16:19:11.594145Z","iopub.execute_input":"2022-03-14T16:19:11.594552Z","iopub.status.idle":"2022-03-14T16:19:15.197485Z","shell.execute_reply.started":"2022-03-14T16:19:11.594516Z","shell.execute_reply":"2022-03-14T16:19:15.196821Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\nModel config DistilBertConfig {\n  \"_name_or_path\": \"distilbert-base-uncased\",\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForMaskedLM\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\",\n    \"3\": \"LABEL_3\",\n    \"4\": \"LABEL_4\"\n  },\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2,\n    \"LABEL_3\": 3,\n    \"LABEL_4\": 4\n  },\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.15.0\",\n  \"vocab_size\": 30522\n}\n\nloading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\nSome weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=5,\n    weight_decay=0.01,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_imdb[\"train\"],\n    #eval_dataset=tokenized_imdb[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T16:19:15.198614Z","iopub.execute_input":"2022-03-14T16:19:15.199103Z","iopub.status.idle":"2022-03-14T16:19:19.538557Z","shell.execute_reply.started":"2022-03-14T16:19:15.199061Z","shell.execute_reply":"2022-03-14T16:19:19.537866Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"PyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence.\n***** Running training *****\n  Num examples = 162\n  Num Epochs = 5\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 105\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [105/105 00:04, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=105, training_loss=0.8969070434570312, metrics={'train_runtime': 4.1941, 'train_samples_per_second': 193.127, 'train_steps_per_second': 25.035, 'total_flos': 6916099617900.0, 'train_loss': 0.8969070434570312, 'epoch': 5.0})"},"metadata":{}}]}]}